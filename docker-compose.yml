version: '3.8'

services:
  # Apache Zookeeper - Required for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "127.0.0.1:2181:2181"  # Localhost only - SECURE
    networks:
      - stock-network
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Apache Kafka - Message Broker
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "127.0.0.1:9092:9092"  # Localhost only - SECURE
      - "127.0.0.1:9093:9093"  # Localhost only - SECURE
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
    networks:
      - stock-network
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s

  # PostgreSQL - Real-time Database for Dashboard
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-stock_db}
      POSTGRES_USER: ${POSTGRES_USER:-admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-admin}
    ports:
      - "127.0.0.1:5432:5432"  # Localhost only - SECURE (prevents remote DB attacks)
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    networks:
      - stock-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-admin} -d ${POSTGRES_DB:-stock_db}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Spark Master
  spark-master:
    image: apache/spark:3.5.0
    container_name: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "127.0.0.1:8080:8080"  # Spark Master Web UI - Localhost only - SECURE
      - "127.0.0.1:7077:7077"  # Spark Master port - Localhost only - SECURE
    environment:
      - SPARK_NO_DAEMONIZE=true
    networks:
      - stock-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Spark Processor (Structured Streaming)
  spark-processor:
    build:
      context: ./streaming/spark_job
      dockerfile: Dockerfile
    container_name: spark-processor
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
      spark-master:
        condition: service_healthy
    environment:
      - SPARK_NO_DAEMONIZE=true
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS:-kafka:9092}
      - KAFKA_TOPIC=${KAFKA_TOPIC:-stock-quotes}
      - POSTGRES_HOST=${POSTGRES_HOST:-postgres}
      - POSTGRES_PORT=${POSTGRES_PORT:-5432}
      - POSTGRES_DB=${POSTGRES_DB:-stock_db}
      - POSTGRES_USER=${POSTGRES_USER:-admin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-admin}
      - CHECKPOINT_QUOTES=/u01/checkpoints/quotes_clean
      - CHECKPOINT_METRICS=/u01/checkpoints/metrics_minute
    volumes:
      - /u01/vsp-spark/checkpoints:/u01/checkpoints
    networks:
      - stock-network
    restart: unless-stopped

  # Spark Worker
  spark-worker:
    image: apache/spark:3.5.0
    container_name: spark-worker
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      spark-master:
        condition: service_healthy
    environment:
      - SPARK_NO_DAEMONIZE=true
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    ports:
      - "127.0.0.1:8081:8081"  # Spark Worker Web UI - Localhost only - SECURE
    networks:
      - stock-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Data Producer - Fetch data from vnstock API
  producer:
    build:
      context: .
      dockerfile: producer/Dockerfile
    container_name: stock-producer
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka:9092}
      KAFKA_TOPIC: ${KAFKA_TOPIC:-stock-quotes}
      PRODUCER_INTERVAL: ${PRODUCER_INTERVAL:-300}
      STOCK_SYMBOLS: ${STOCK_SYMBOLS:-}
      TMPDIR: /u01/tmp
      PIP_CACHE_DIR: /u01/pip-cache
    networks:
      - stock-network
    restart: unless-stopped
    volumes:
      - /u01/vsp-producer/tmp:/u01/tmp
      - /u01/vsp-producer/pip-cache:/u01/pip-cache

  # Kafka to PostgreSQL Consumer (replaces Spark processor due to compatibility issues)
  consumer:
    build:
      context: .
      dockerfile: etl/Dockerfile.consumer
    container_name: kafka-consumer
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka:9092}
      KAFKA_TOPIC: ${KAFKA_TOPIC:-stock-quotes}
      KAFKA_GROUP_ID: ${KAFKA_GROUP_ID:-postgres-consumer-group}
      POSTGRES_HOST: ${POSTGRES_HOST:-postgres}
      POSTGRES_PORT: ${POSTGRES_PORT:-5432}
      POSTGRES_DB: ${POSTGRES_DB:-stock_db}
      POSTGRES_USER: ${POSTGRES_USER:-admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-admin}
      BATCH_SIZE: ${BATCH_SIZE:-100}
      BATCH_TIMEOUT: ${BATCH_TIMEOUT:-10}
      TMPDIR: /u01/tmp
      PIP_CACHE_DIR: /u01/pip-cache
    networks:
      - stock-network
    restart: unless-stopped
    volumes:
      - /u01/vsp-consumer/tmp:/u01/tmp
      - /u01/vsp-consumer/pip-cache:/u01/pip-cache

  # Snowflake Sync (Optional - only runs if Snowflake credentials are provided)
  snowflake-sync:
    build:
      context: .
      dockerfile: etl/Dockerfile.sync
    container_name: snowflake-sync
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      POSTGRES_HOST: ${POSTGRES_HOST:-postgres}
      POSTGRES_PORT: ${POSTGRES_PORT:-5432}
      POSTGRES_DB: ${POSTGRES_DB:-stock_db}
      POSTGRES_USER: ${POSTGRES_USER:-admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-admin}
      SNOWFLAKE_ACCOUNT: ${SNOWFLAKE_ACCOUNT:-}
      SNOWFLAKE_USER: ${SNOWFLAKE_USER:-}
      SNOWFLAKE_PASSWORD: ${SNOWFLAKE_PASSWORD:-}
      SNOWFLAKE_WAREHOUSE: ${SNOWFLAKE_WAREHOUSE:-COMPUTE_WH}
      SNOWFLAKE_DATABASE: ${SNOWFLAKE_DATABASE:-STOCKS}
      SNOWFLAKE_SCHEMA: ${SNOWFLAKE_SCHEMA:-PUBLIC}
      SNOWFLAKE_ROLE: ${SNOWFLAKE_ROLE:-ACCOUNTADMIN}
      SYNC_INTERVAL: ${SYNC_INTERVAL:-300}  # Sync every 5 minutes
    networks:
      - stock-network
    restart: unless-stopped
    profiles:
      - snowflake  # Only start if explicitly requested with --profile snowflake

  # Streamlit Dashboard
  dashboard:
    build:
      context: .
      dockerfile: dashboard/Dockerfile
    container_name: stock-dashboard
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka:9092}
      KAFKA_HOST: ${KAFKA_HOST:-kafka}
      KAFKA_PORT: ${KAFKA_PORT:-9092}
      POSTGRES_HOST: ${POSTGRES_HOST:-postgres}
      POSTGRES_PORT: ${POSTGRES_PORT:-5432}
      POSTGRES_DB: ${POSTGRES_DB:-stock_db}
      POSTGRES_USER: ${POSTGRES_USER:-admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-admin}
      DASHBOARD_REFRESH_INTERVAL: ${DASHBOARD_REFRESH_INTERVAL:-3}
      TMPDIR: /u01/tmp
      PIP_CACHE_DIR: /u01/pip-cache
      STREAMLIT_CACHE_DIR: /u01/streamlit-cache
    ports:
      - "127.0.0.1:8501:8501"  # Dashboard - Localhost only - SECURE (use SSH tunnel or VPN for remote access)
    networks:
      - stock-network
    restart: unless-stopped
    command: streamlit run dashboard_hybrid.py --server.port=8501 --server.address=0.0.0.0 --server.headless=true --server.runOnSave=true --server.fileWatcherType=poll
    volumes:
      - /u01/vsp-dashboard/tmp:/u01/tmp
      - /u01/vsp-dashboard/pip-cache:/u01/pip-cache
      - /u01/vsp-dashboard/streamlit-cache:/u01/streamlit-cache

  # pgAdmin - PostgreSQL Web UI
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL:-admin@example.com}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD:-admin}
      PGADMIN_CONFIG_SERVER_MODE: 'False'
      PGADMIN_CONFIG_MASTER_PASSWORD_REQUIRED: 'False'
      PGADMIN_DISABLE_POSTFIX: 'true'
    ports:
      - "127.0.0.1:5050:80"  # pgAdmin UI - Localhost only - SECURE
    volumes:
      - pgadmin-data:/var/lib/pgadmin
      - ./pgadmin-config/servers.json:/pgadmin4/servers.json:ro
    networks:
      - stock-network
    restart: unless-stopped

networks:
  stock-network:
    driver: bridge

volumes:
  postgres-data:
    driver: local
  pgadmin-data:
    driver: local

