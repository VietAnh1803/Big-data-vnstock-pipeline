# üì∏ H∆∞·ªõng D·∫´n Ch·ª•p M√†n H√¨nh Cho B√°o C√°o

## üéØ T·ªïng Quan

T√†i li·ªáu n√†y h∆∞·ªõng d·∫´n c√°c m√†n h√¨nh c·∫ßn ch·ª•p t·ª´ Kafka UI v√† Spark UI ƒë·ªÉ tr√¨nh b√†y trong b√°o c√°o.

---

## üìä PH·∫¶N 1: KAFKA UI

**URL:** http://localhost:8080/kafka/ ho·∫∑c http://localhost:8081

### 1.1. **Topics Overview** (Trang ch·ªß Kafka UI)
**V·ªã tr√≠:** Trang ch·ªß sau khi login
**C·∫ßn ch·ª•p:**
- Danh s√°ch topics (ch·ªâ th·∫•y `realtime_quotes`)
- S·ªë l∆∞·ª£ng partitions: **12 partitions**
- Topic name: `realtime_quotes`
- **Gi·∫£i th√≠ch:** "Kafka topic ch√≠nh ƒë·ªÉ stream d·ªØ li·ªáu real-time t·ª´ producer"

### 1.2. **Topic Details - realtime_quotes**
**V·ªã tr√≠:** Click v√†o topic `realtime_quotes`
**C·∫ßn ch·ª•p:**
- **Partitions tab:**
  - 12 partitions (0-11)
  - Replication Factor: 1
  - Segment size: 1GB
- **Messages tab:**
  - Total messages trong topic
  - Message rate (messages/second)
- **Gi·∫£i th√≠ch:** 
  - "12 partitions ƒë·ªÉ scale horizontal v√† parallel processing"
  - "Message format: JSON v·ªõi schema chu·∫©n"

### 1.3. **Topic Configuration**
**V·ªã tr√≠:** Trong topic details ‚Üí Configuration tab
**C·∫ßn ch·ª•p:**
- Retention policy (7 days)
- Segment size
- Compression settings
- **Gi·∫£i th√≠ch:** "C·∫•u h√¨nh retention v√† compression ƒë·ªÉ t·ªëi ∆∞u storage"

### 1.4. **Messages Browser** (Optional)
**V·ªã tr√≠:** Trong topic ‚Üí Messages tab
**C·∫ßn ch·ª•p:**
- Sample message format
- Message key (ticker)
- Message value (JSON payload)
- **Gi·∫£i th√≠ch:** "Message structure: key = ticker, value = JSON v·ªõi price, volume, change, etc."

---

## ‚ö° PH·∫¶N 2: SPARK UI

**URL:** http://localhost:8080/spark/ ho·∫∑c http://localhost:4041

### 2.1. **Spark Application Overview**
**V·ªã tr√≠:** Trang ch·ªß Spark UI
**C·∫ßn ch·ª•p:**
- Application name: "Vietnam Stock Spark Consumer"
- Application ID: `local-1762249055177`
- Status: **Running**
- Duration: Th·ªùi gian ch·∫°y
- **Gi·∫£i th√≠ch:** "Spark Structured Streaming application ƒëang ch·∫°y 24/7"

### 2.2. **Jobs Tab - Active Jobs**
**V·ªã tr√≠:** Spark UI ‚Üí Jobs tab
**C·∫ßn ch·ª•p:**
- Active jobs list
- Completed jobs count
- Job duration v√† status
- **Gi·∫£i th√≠ch:** "Spark x·ª≠ l√Ω micro-batches m·ªói 15 gi√¢y, m·ªói job = 1 batch processing"

### 2.3. **Stages Tab** (Quan tr·ªçng)
**V·ªã tr√≠:** Spark UI ‚Üí Stages tab
**C·∫ßn ch·ª•p:**
- Stage details v·ªõi:
  - Input size (data t·ª´ Kafka)
  - Output size (data sau processing)
  - Shuffle read/write
  - Duration
- **Gi·∫£i th√≠ch:** 
  - "Input size: l∆∞·ª£ng data ƒë·ªçc t·ª´ Kafka"
  - "Shuffle partitions: 200 ƒë·ªÉ parallel processing"
  - "Processing time: < 5 gi√¢y cho m·ªói batch"

### 2.4. **Storage Tab** (Optional)
**V·ªã tr√≠:** Spark UI ‚Üí Storage tab
**C·∫ßn ch·ª•p:**
- Cached data (n·∫øu c√≥)
- **Gi·∫£i th√≠ch:** "Spark caching ƒë·ªÉ optimize repeated queries"

### 2.5. **Environment Tab** (Quan tr·ªçng)
**V·ªã tr√≠:** Spark UI ‚Üí Environment tab
**C·∫ßn ch·ª•p:**
- Spark Properties:
  - `spark.sql.streaming.checkpointLocation`: `/tmp/spark-checkpoint`
  - `spark.sql.shuffle.partitions`: `200`
  - `spark.sql.streaming.kafka.useDeprecatedOffsetFetching`: `false`
- **Gi·∫£i th√≠ch:** 
  - "Checkpoint location: Spark l∆∞u offsets ƒë·ªÉ fault tolerance"
  - "Shuffle partitions: 200 ƒë·ªÉ scale processing"
  - "Kafka integration: d√πng latest Kafka consumer API"

### 2.6. **Executors Tab**
**V·ªã tr√≠:** Spark UI ‚Üí Executors tab
**C·∫ßn ch·ª•p:**
- Number of executors
- Memory usage
- Cores used
- Tasks completed
- **Gi·∫£i th√≠ch:** "Resource usage: CPU cores, memory allocation"

### 2.7. **SQL Tab** (N·∫øu c√≥)
**V·ªã tr√≠:** Spark UI ‚Üí SQL tab
**C·∫ßn ch·ª•p:**
- Query execution plans
- Query duration
- **Gi·∫£i th√≠ch:** "Spark SQL queries cho data transformation"

---

## üìà PH·∫¶N 3: SPARK STREAMING (Quan tr·ªçng nh·∫•t)

**V·ªã tr√≠:** Spark UI ‚Üí Tab "Streaming" (n·∫øu c√≥) ho·∫∑c trong Jobs tab t√¨m streaming jobs

### 3.1. **Streaming Query Statistics**
**C·∫ßn ch·ª•p:**
- **Input Rate:** Messages/second ƒë·ªçc t·ª´ Kafka
- **Processing Rate:** Messages/second x·ª≠ l√Ω
- **Batch Duration:** Th·ªùi gian x·ª≠ l√Ω m·ªói batch (~15 gi√¢y)
- **Total Processed Records:** T·ªïng s·ªë records ƒë√£ x·ª≠ l√Ω
- **Gi·∫£i th√≠ch:** 
  - "Micro-batch processing: m·ªói 15 gi√¢y Spark ƒë·ªçc v√† x·ª≠ l√Ω m·ªôt batch"
  - "Input rate vs Processing rate: cho th·∫•y Spark c√≥ theo k·ªãp Kafka kh√¥ng"

### 3.2. **Batch Processing Details**
**C·∫ßn ch·ª•p:**
- List of recent batches
- Batch ID v√† timestamp
- Records per batch
- Processing time
- **Gi·∫£i th√≠ch:** "M·ªói batch x·ª≠ l√Ω ~100-300 records, th·ªùi gian < 5 gi√¢y"

---

## üóÑÔ∏è PH·∫¶N 4: DATABASE (Optional nh∆∞ng t·ªët)

### 4.1. **Database Statistics**
**Command:**
```sql
SELECT 
    COUNT(*) as total_records,
    COUNT(DISTINCT ticker) as unique_tickers,
    MIN(time) as earliest_record,
    MAX(time) as latest_record,
    MAX(time) - MIN(time) as data_range
FROM realtime_quotes;
```

**Gi·∫£i th√≠ch:** "TimescaleDB hypertable v·ªõi compression v√† retention policies"

---

## üìã TH·ª® T·ª∞ TR√åNH B√ÄY ƒê·ªÄ XU·∫§T

### Slide 1: Architecture Overview
- Kafka UI ‚Üí Topics overview
- Gi·∫£i th√≠ch: "Kafka l√†m streaming bus, topic `realtime_quotes` v·ªõi 12 partitions"

### Slide 2: Kafka Topic Details
- Kafka UI ‚Üí Topic `realtime_quotes` details
- Partitions, messages, configuration
- Gi·∫£i th√≠ch: "12 partitions cho parallel processing, retention 7 ng√†y"

### Slide 3: Spark Application
- Spark UI ‚Üí Application overview
- Jobs, Stages
- Gi·∫£i th√≠ch: "Spark Structured Streaming consumer x·ª≠ l√Ω real-time"

### Slide 4: Spark Processing Performance
- Spark UI ‚Üí Stages tab
- Input/Output sizes, duration
- Gi·∫£i th√≠ch: "Processing time < 5s, throughput cao"

### Slide 5: Streaming Metrics
- Spark UI ‚Üí Streaming tab (n·∫øu c√≥) ho·∫∑c Jobs v·ªõi streaming details
- Input rate, processing rate
- Gi·∫£i th√≠ch: "Spark theo k·ªãp Kafka, kh√¥ng c√≥ lag ƒë√°ng k·ªÉ"

### Slide 6: Resource Usage
- Spark UI ‚Üí Executors tab
- CPU, Memory usage
- Gi·∫£i th√≠ch: "Resource utilization hi·ªáu qu·∫£"

---

## üí° TIPS CHO B√ÅO C√ÅO

1. **Highlight con s·ªë c·ª• th·ªÉ:**
   - 12 partitions
   - 15 gi√¢y batch interval
   - 200 shuffle partitions
   - 50,000 max offsets per trigger

2. **Gi·∫£i th√≠ch l·ª£i √≠ch:**
   - "12 partitions ‚Üí parallel processing ‚Üí high throughput"
   - "Checkpoint ‚Üí fault tolerance ‚Üí kh√¥ng m·∫•t data"
   - "Micro-batch 15s ‚Üí low latency ‚Üí real-time processing"

3. **So s√°nh v·ªõi alternatives:**
   - "Spark Structured Streaming vs traditional Kafka Consumer"
   - "Checkpoint-based offsets vs Consumer Groups"
   - "Why 12 partitions? Scalability v√† load balancing"

4. **Performance metrics:**
   - "Input rate: X messages/sec"
   - "Processing time: < 5 seconds/batch"
   - "Total processed: Y million records"

---

## üîó QUICK ACCESS LINKS

```bash
# Kafka UI
http://localhost:8080/kafka/     # Via proxy (c·∫ßn login)
http://localhost:8081            # Direct (c·∫ßn login)

# Spark UI  
http://localhost:8080/spark/     # Via proxy (c·∫ßn login)
http://localhost:4041            # Direct (kh√¥ng c·∫ßn login)

# Dashboard
http://localhost:8501            # Kh√¥ng c·∫ßn login
```

---

## üìù NOTES

- **Kafka UI:** C·∫ßn login (admin / password t·ª´ .env)
- **Spark UI:** Direct access kh√¥ng c·∫ßn login, nh∆∞ng qua proxy c·∫ßn login
- **Consumer Groups:** Kh√¥ng c√≥ trong Kafka UI v√¨ Spark kh√¥ng d√πng consumer groups
- **Lag:** Ki·ªÉm tra b·∫±ng script `calculate_lag.sh`, kh√¥ng qua Kafka UI

---

**Ch√∫c b·∫°n b√°o c√°o th√†nh c√¥ng! üéâ**

